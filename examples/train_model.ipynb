{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02893dd",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41bfeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2516b5c3730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from simulator.objects.policies.architectures import ModelTask\n",
    "from simulator.objects.policies.architectures.perceptron import MultiLayerPerceptron\n",
    "from simulator.objects.stock import Stock\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddbe4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_stock_features(n_stocks: int) -> torch.Tensor:\n",
    "    output = []\n",
    "    noise_dist = torch.distributions.Normal(loc=0, scale=0.001)\n",
    "    for _ in range(n_stocks):\n",
    "        cash = torch.rand(size=(1,)) * 110000 - 10000\n",
    "        earning_value_of_assets = torch.rand(size=(1,)) * 20000 + 10000\n",
    "        latest_quarterly_earnings = torch.rand(size=(1,)) * 20000 + 10000\n",
    "        start_price = torch.rand(size=(1,)) * 1000 + 10\n",
    "        price_slope = torch.rand(size=(1,)) * 0.01 - 0.005\n",
    "        growth_component = start_price + price_slope * torch.arange(0, 1825)\n",
    "        noise_component = noise_dist.sample(sample_shape=(1825,))\n",
    "        price_history = growth_component + noise_component\n",
    "        quality_of_leadership = torch.rand(size=(1,))\n",
    "        stock = Stock(\n",
    "            cash=cash.item(),\n",
    "            earning_value_of_assets=earning_value_of_assets.item(),\n",
    "            latest_quarterly_earnings=latest_quarterly_earnings.item(),\n",
    "            price_history=price_history.numpy(),\n",
    "            quality_of_leadership=quality_of_leadership.item(),\n",
    "            stock_volatility=0.5,\n",
    "        )\n",
    "\n",
    "        output.append(np.append(stock.get_stock_features(), 0))\n",
    "\n",
    "    return torch.tensor(output)\n",
    "\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78affda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c57e3d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_4576\\226733360.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  return torch.tensor(output)\n",
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_4576\\226733360.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data = torch.tensor(data, dtype=torch.float32)\n",
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_4576\\226733360.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 5000\n",
    "VALID_RATIO = 0.15\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "# NOTE: SWITCH TO PERCENT ERROR LOSS OR SOME VARIANT\n",
    "\n",
    "stock_features = generate_example_stock_features(N_SAMPLES)\n",
    "stock_labels = stock_features[:, 0]\n",
    "\n",
    "stock_dataset = StockDataset(stock_features, stock_labels)\n",
    "val_length = int(N_SAMPLES * VALID_RATIO)\n",
    "test_length = int(N_SAMPLES * TEST_RATIO)\n",
    "train_length = N_SAMPLES - (val_length + test_length)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    stock_dataset, lengths=[train_length, val_length, test_length]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=val_length, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_length, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a173d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; training_loss: 302519.375; validation_loss: 337940.90625\n",
      "Epoch: 1; training_loss: 367340.9375; validation_loss: 337773.21875\n",
      "Epoch: 2; training_loss: 332988.03125; validation_loss: 337579.21875\n",
      "Epoch: 3; training_loss: 336974.0625; validation_loss: 337354.15625\n",
      "Epoch: 4; training_loss: 373380.5; validation_loss: 337092.59375\n",
      "Epoch: 5; training_loss: 327376.28125; validation_loss: 336789.40625\n",
      "Epoch: 6; training_loss: 328868.34375; validation_loss: 336435.21875\n",
      "Epoch: 7; training_loss: 334127.375; validation_loss: 336018.5\n",
      "Epoch: 8; training_loss: 312977.0; validation_loss: 335527.15625\n",
      "Epoch: 9; training_loss: 303266.40625; validation_loss: 334944.625\n",
      "Epoch: 10; training_loss: 305365.5625; validation_loss: 334247.65625\n",
      "Epoch: 11; training_loss: 409364.875; validation_loss: 333409.625\n",
      "Epoch: 12; training_loss: 336922.09375; validation_loss: 332413.9375\n",
      "Epoch: 13; training_loss: 342041.15625; validation_loss: 331210.71875\n",
      "Epoch: 14; training_loss: 325367.3125; validation_loss: 329738.5625\n",
      "Epoch: 15; training_loss: 300533.1875; validation_loss: 327959.34375\n",
      "Epoch: 16; training_loss: 362202.375; validation_loss: 325819.65625\n",
      "Epoch: 17; training_loss: 337439.40625; validation_loss: 323157.75\n",
      "Epoch: 18; training_loss: 342048.28125; validation_loss: 319863.625\n",
      "Epoch: 19; training_loss: 291893.875; validation_loss: 315791.34375\n",
      "Epoch: 20; training_loss: 253677.9375; validation_loss: 310751.25\n",
      "Epoch: 21; training_loss: 323458.1875; validation_loss: 304632.84375\n",
      "Epoch: 22; training_loss: 298405.5625; validation_loss: 297423.5\n",
      "Epoch: 23; training_loss: 298935.46875; validation_loss: 289146.1875\n",
      "Epoch: 24; training_loss: 291475.96875; validation_loss: 280474.8125\n",
      "Epoch: 25; training_loss: 234769.828125; validation_loss: 273139.90625\n",
      "Epoch: 26; training_loss: 213246.5; validation_loss: 271433.9375\n",
      "Epoch: 27; training_loss: 267761.375; validation_loss: 281183.875\n",
      "Epoch: 28; training_loss: 275214.15625; validation_loss: 288705.40625\n",
      "Epoch: 29; training_loss: 247275.09375; validation_loss: 288204.25\n",
      "Epoch: 30; training_loss: 263933.375; validation_loss: 277784.375\n",
      "Epoch: 31; training_loss: 261072.15625; validation_loss: 271016.4375\n",
      "Epoch: 32; training_loss: 250442.96875; validation_loss: 268467.46875\n",
      "Epoch: 33; training_loss: 310432.8125; validation_loss: 268548.5625\n",
      "Epoch: 34; training_loss: 325520.96875; validation_loss: 269905.125\n",
      "Epoch: 35; training_loss: 242605.59375; validation_loss: 271181.15625\n",
      "Epoch: 36; training_loss: 254406.671875; validation_loss: 271968.8125\n",
      "Epoch: 37; training_loss: 272091.375; validation_loss: 272102.65625\n",
      "Epoch: 38; training_loss: 310464.375; validation_loss: 271431.96875\n",
      "Epoch: 39; training_loss: 221807.203125; validation_loss: 270422.65625\n",
      "Epoch: 40; training_loss: 283554.65625; validation_loss: 268915.375\n",
      "Epoch: 41; training_loss: 255886.625; validation_loss: 267132.28125\n",
      "Epoch: 42; training_loss: 250503.84375; validation_loss: 264942.3125\n",
      "Epoch: 43; training_loss: 223303.015625; validation_loss: 262765.9375\n",
      "Epoch: 44; training_loss: 224387.6875; validation_loss: 260676.6875\n",
      "Epoch: 45; training_loss: 245576.53125; validation_loss: 259461.15625\n",
      "Epoch: 46; training_loss: 261651.875; validation_loss: 259802.5625\n",
      "Epoch: 47; training_loss: 245843.28125; validation_loss: 262626.0\n",
      "Epoch: 48; training_loss: 279651.34375; validation_loss: 265578.46875\n",
      "Epoch: 49; training_loss: 244728.046875; validation_loss: 263808.375\n",
      "Epoch: 50; training_loss: 235969.125; validation_loss: 258194.90625\n",
      "Epoch: 51; training_loss: 252974.28125; validation_loss: 253700.78125\n",
      "Epoch: 52; training_loss: 244294.9375; validation_loss: 250877.390625\n",
      "Epoch: 53; training_loss: 232036.25; validation_loss: 249887.015625\n",
      "Epoch: 54; training_loss: 213270.75; validation_loss: 249416.0625\n",
      "Epoch: 55; training_loss: 242480.40625; validation_loss: 248156.671875\n",
      "Epoch: 56; training_loss: 227853.28125; validation_loss: 245738.796875\n",
      "Epoch: 57; training_loss: 210014.40625; validation_loss: 241918.671875\n",
      "Epoch: 58; training_loss: 191326.390625; validation_loss: 237431.671875\n",
      "Epoch: 59; training_loss: 240480.46875; validation_loss: 234011.515625\n",
      "Epoch: 60; training_loss: 194130.828125; validation_loss: 234589.953125\n",
      "Epoch: 61; training_loss: 199363.21875; validation_loss: 232777.984375\n",
      "Epoch: 62; training_loss: 256756.4375; validation_loss: 235581.953125\n",
      "Epoch: 63; training_loss: 178265.34375; validation_loss: 225506.734375\n",
      "Epoch: 64; training_loss: 200801.875; validation_loss: 217349.734375\n",
      "Epoch: 65; training_loss: 184793.1875; validation_loss: 211402.53125\n",
      "Epoch: 66; training_loss: 217392.15625; validation_loss: 207652.515625\n",
      "Epoch: 67; training_loss: 156498.5625; validation_loss: 205325.3125\n",
      "Epoch: 68; training_loss: 183375.203125; validation_loss: 204246.359375\n",
      "Epoch: 69; training_loss: 201541.59375; validation_loss: 203584.40625\n",
      "Epoch: 70; training_loss: 213474.125; validation_loss: 203470.078125\n",
      "Epoch: 71; training_loss: 229987.28125; validation_loss: 206118.859375\n",
      "Epoch: 72; training_loss: 165672.3125; validation_loss: 208906.0625\n",
      "Epoch: 73; training_loss: 200639.609375; validation_loss: 210277.4375\n",
      "Epoch: 74; training_loss: 235282.0625; validation_loss: 211505.28125\n",
      "Epoch: 75; training_loss: 192074.46875; validation_loss: 206483.109375\n",
      "Epoch: 76; training_loss: 229534.421875; validation_loss: 202930.0\n",
      "Epoch: 77; training_loss: 178660.078125; validation_loss: 202419.9375\n",
      "Epoch: 78; training_loss: 205275.21875; validation_loss: 203374.15625\n",
      "Epoch: 79; training_loss: 193307.25; validation_loss: 204714.921875\n",
      "Epoch: 80; training_loss: 167822.59375; validation_loss: 205760.984375\n",
      "Epoch: 81; training_loss: 203587.15625; validation_loss: 205161.8125\n",
      "Epoch: 82; training_loss: 155105.265625; validation_loss: 203096.546875\n",
      "Epoch: 83; training_loss: 173736.046875; validation_loss: 201502.1875\n",
      "Epoch: 84; training_loss: 180334.640625; validation_loss: 200470.84375\n",
      "Epoch: 85; training_loss: 177182.484375; validation_loss: 200218.828125\n",
      "Epoch: 86; training_loss: 243855.9375; validation_loss: 200400.078125\n",
      "Epoch: 87; training_loss: 221360.265625; validation_loss: 201390.953125\n",
      "Epoch: 88; training_loss: 173307.8125; validation_loss: 202938.796875\n",
      "Epoch: 89; training_loss: 186766.90625; validation_loss: 204311.578125\n",
      "Epoch: 90; training_loss: 190036.046875; validation_loss: 203837.28125\n",
      "Epoch: 91; training_loss: 223752.03125; validation_loss: 201451.046875\n",
      "Epoch: 92; training_loss: 194588.875; validation_loss: 197912.71875\n",
      "Epoch: 93; training_loss: 164144.9375; validation_loss: 198107.03125\n",
      "Epoch: 94; training_loss: 169692.203125; validation_loss: 200341.421875\n",
      "Epoch: 95; training_loss: 185164.96875; validation_loss: 202117.484375\n",
      "Epoch: 96; training_loss: 169273.65625; validation_loss: 201870.484375\n",
      "Epoch: 97; training_loss: 228699.75; validation_loss: 200159.078125\n",
      "Epoch: 98; training_loss: 181294.8125; validation_loss: 198270.328125\n",
      "Epoch: 99; training_loss: 180273.828125; validation_loss: 196924.078125\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "\n",
    "model = MultiLayerPerceptron(\n",
    "    in_channels=14,\n",
    "    hidden_channels=[16, 32],\n",
    "    n_classes=1,\n",
    "    model_task=ModelTask.REGRESSOR,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    val_features, val_labels = next(iter(val_dataloader))\n",
    "\n",
    "    train_features = train_features.to(device)\n",
    "    train_labels = train_labels.to(device)\n",
    "    val_features = val_features.to(device)\n",
    "    val_labels = val_labels.to(device)\n",
    "\n",
    "    preds = model(train_features)\n",
    "    loss = loss_fun(preds, train_labels)\n",
    "\n",
    "    val_preds = model(val_features)\n",
    "    val_loss = loss_fun(val_preds, val_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {i}; training_loss: {loss}; validation_loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62403a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(201784.4531, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "print(loss_fun(model(test_features.to(device)), test_labels.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaad38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_high_prices.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
