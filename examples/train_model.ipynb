{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02893dd",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41bfeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19d2dcb36f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from simulator.objects.policies.architectures.perceptron import MultiLayerPerceptron\n",
    "from simulator.objects.policies.architectures import ModelTask\n",
    "from simulator.objects.stock import Stock\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ddbe4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_stock_features(n_stocks: int) -> torch.Tensor:\n",
    "    output = []\n",
    "    noise_dist = torch.distributions.Normal(loc=0, scale=0.001)\n",
    "    for _ in range(n_stocks):\n",
    "        cash = torch.rand(size=(1,)) * 10000 - 2000\n",
    "        earning_value_of_assets = torch.rand(size=(1,)) * 20000\n",
    "        latest_quarterly_earnings = torch.rand(size=(1,)) * 20000\n",
    "        start_price = torch.rand(size=(1,)) * 90 + 10\n",
    "        price_slope = torch.rand(size=(1,)) * 0.01 - 0.005\n",
    "        growth_component = start_price + price_slope * torch.arange(0, 1825)\n",
    "        noise_component = noise_dist.sample(sample_shape=(1825,))\n",
    "        price_history = growth_component + noise_component\n",
    "        quality_of_leadership = torch.rand(size=(1,))\n",
    "        stock = Stock(\n",
    "            cash=cash.item(),\n",
    "            earning_value_of_assets=earning_value_of_assets.item(),\n",
    "            latest_quarterly_earnings=latest_quarterly_earnings.item(),\n",
    "            price_history=price_history.numpy(),\n",
    "            quality_of_leadership=quality_of_leadership.item(),\n",
    "            stock_volatility=0.5\n",
    "        )\n",
    "\n",
    "        output.append(np.append(stock.get_stock_features(), 0))\n",
    "\n",
    "    return torch.tensor(output)\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78affda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c57e3d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_30128\\2442711737.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data = torch.tensor(data, dtype=torch.float32)\n",
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_30128\\2442711737.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 5000\n",
    "VALID_RATIO = 0.15\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "stock_features = generate_example_stock_features(N_SAMPLES)\n",
    "stock_labels = stock_features[:, 0]\n",
    "\n",
    "stock_dataset = StockDataset(stock_features, stock_labels)\n",
    "val_length = int(N_SAMPLES * VALID_RATIO)\n",
    "test_length = int(N_SAMPLES * TEST_RATIO)\n",
    "train_length = N_SAMPLES - (val_length + test_length)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(stock_dataset, lengths=[train_length, val_length, test_length])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=val_length, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_length, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a173d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; training_loss: 11076.826171875; validation_loss: 13681.4189453125\n",
      "Epoch: 1; training_loss: 9682.2861328125; validation_loss: 10122.6611328125\n",
      "Epoch: 2; training_loss: 7392.1875; validation_loss: 8367.1328125\n",
      "Epoch: 3; training_loss: 7529.39794921875; validation_loss: 7611.2646484375\n",
      "Epoch: 4; training_loss: 7787.353515625; validation_loss: 7084.88916015625\n",
      "Epoch: 5; training_loss: 6195.8818359375; validation_loss: 6310.4658203125\n",
      "Epoch: 6; training_loss: 5978.92529296875; validation_loss: 5427.51904296875\n",
      "Epoch: 7; training_loss: 4515.642578125; validation_loss: 4496.30419921875\n",
      "Epoch: 8; training_loss: 3599.224609375; validation_loss: 3719.7138671875\n",
      "Epoch: 9; training_loss: 3035.80615234375; validation_loss: 3141.724609375\n",
      "Epoch: 10; training_loss: 3286.528564453125; validation_loss: 2744.127685546875\n",
      "Epoch: 11; training_loss: 2248.07177734375; validation_loss: 2505.010986328125\n",
      "Epoch: 12; training_loss: 2094.518798828125; validation_loss: 2356.3623046875\n",
      "Epoch: 13; training_loss: 2151.389404296875; validation_loss: 2209.02783203125\n",
      "Epoch: 14; training_loss: 1966.1807861328125; validation_loss: 2053.06689453125\n",
      "Epoch: 15; training_loss: 1389.7178955078125; validation_loss: 1833.6326904296875\n",
      "Epoch: 16; training_loss: 1599.6436767578125; validation_loss: 1615.9794921875\n",
      "Epoch: 17; training_loss: 1095.9049072265625; validation_loss: 1453.671630859375\n",
      "Epoch: 18; training_loss: 1317.9918212890625; validation_loss: 1377.8514404296875\n",
      "Epoch: 19; training_loss: 1083.3829345703125; validation_loss: 1375.994873046875\n",
      "Epoch: 20; training_loss: 1258.7890625; validation_loss: 1412.13134765625\n",
      "Epoch: 21; training_loss: 1398.417236328125; validation_loss: 1438.6787109375\n",
      "Epoch: 22; training_loss: 1415.00732421875; validation_loss: 1456.36767578125\n",
      "Epoch: 23; training_loss: 1358.5; validation_loss: 1439.74560546875\n",
      "Epoch: 24; training_loss: 1193.1253662109375; validation_loss: 1399.69482421875\n",
      "Epoch: 25; training_loss: 1322.241455078125; validation_loss: 1368.4461669921875\n",
      "Epoch: 26; training_loss: 1295.931640625; validation_loss: 1342.7218017578125\n",
      "Epoch: 27; training_loss: 1281.56103515625; validation_loss: 1333.1314697265625\n",
      "Epoch: 28; training_loss: 1234.969482421875; validation_loss: 1338.6595458984375\n",
      "Epoch: 29; training_loss: 1261.204345703125; validation_loss: 1334.9935302734375\n",
      "Epoch: 30; training_loss: 1072.7584228515625; validation_loss: 1323.53369140625\n",
      "Epoch: 31; training_loss: 1268.2320556640625; validation_loss: 1299.1710205078125\n",
      "Epoch: 32; training_loss: 1133.054443359375; validation_loss: 1268.9912109375\n",
      "Epoch: 33; training_loss: 1168.321044921875; validation_loss: 1244.85009765625\n",
      "Epoch: 34; training_loss: 1272.873291015625; validation_loss: 1235.5126953125\n",
      "Epoch: 35; training_loss: 931.9915161132812; validation_loss: 1245.259521484375\n",
      "Epoch: 36; training_loss: 1085.171630859375; validation_loss: 1268.207763671875\n",
      "Epoch: 37; training_loss: 1248.964599609375; validation_loss: 1273.8248291015625\n",
      "Epoch: 38; training_loss: 1333.392578125; validation_loss: 1255.4786376953125\n",
      "Epoch: 39; training_loss: 1043.5439453125; validation_loss: 1219.1331787109375\n",
      "Epoch: 40; training_loss: 1023.3619995117188; validation_loss: 1173.6502685546875\n",
      "Epoch: 41; training_loss: 829.0750732421875; validation_loss: 1138.35302734375\n",
      "Epoch: 42; training_loss: 1159.62646484375; validation_loss: 1117.1119384765625\n",
      "Epoch: 43; training_loss: 1080.9141845703125; validation_loss: 1102.127197265625\n",
      "Epoch: 44; training_loss: 866.24267578125; validation_loss: 1094.4229736328125\n",
      "Epoch: 45; training_loss: 1024.068359375; validation_loss: 1090.44970703125\n",
      "Epoch: 46; training_loss: 982.1088256835938; validation_loss: 1086.1119384765625\n",
      "Epoch: 47; training_loss: 880.4364013671875; validation_loss: 1076.9951171875\n",
      "Epoch: 48; training_loss: 1064.0853271484375; validation_loss: 1070.2806396484375\n",
      "Epoch: 49; training_loss: 829.8580322265625; validation_loss: 1067.677001953125\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "\n",
    "model = MultiLayerPerceptron(\n",
    "    in_channels=14,\n",
    "    hidden_channels=[16, 32],\n",
    "    n_classes=1, \n",
    "    model_task=ModelTask.REGRESSOR\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    val_features, val_labels = next(iter(val_dataloader))\n",
    "\n",
    "    train_features = train_features.to(device)\n",
    "    train_labels = train_labels.to(device)\n",
    "    val_features = val_features.to(device)\n",
    "    val_labels = val_labels.to(device)\n",
    "\n",
    "    preds = model(train_features)\n",
    "    loss = loss_fun(preds, train_labels)\n",
    "\n",
    "    val_preds = model(val_features)\n",
    "    val_loss = loss_fun(val_preds, val_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {i}; training_loss: {loss}; validation_loss: {val_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62403a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(969.8900, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "print(loss_fun(model(test_features.to(device)), test_labels.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaad38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
