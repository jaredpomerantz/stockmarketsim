{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02893dd",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41bfeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19d2dcb36f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from simulator.objects.policies.architectures.perceptron import MultiLayerPerceptron\n",
    "from simulator.objects.policies.architectures import ModelTask\n",
    "from simulator.objects.stock import Stock\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddbe4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_stock_features(n_stocks: int) -> torch.Tensor:\n",
    "    output = []\n",
    "    noise_dist = torch.distributions.Normal(loc=0, scale=0.001)\n",
    "    for _ in range(n_stocks):\n",
    "        cash = torch.rand(size=(1,)) * 10000 - 2000\n",
    "        earning_value_of_assets = torch.rand(size=(1,)) * 20000\n",
    "        latest_quarterly_earnings = torch.rand(size=(1,)) * 20000\n",
    "        start_price = torch.rand(size=(1,)) * 90 + 10\n",
    "        price_slope = torch.rand(size=(1,)) * 0.01 - 0.005\n",
    "        growth_component = start_price + price_slope * torch.arange(0, 1825)\n",
    "        noise_component = noise_dist.sample(sample_shape=(1825,))\n",
    "        price_history = growth_component + noise_component\n",
    "        quality_of_leadership = torch.rand(size=(1,))\n",
    "        stock = Stock(\n",
    "            cash=cash.item(),\n",
    "            earning_value_of_assets=earning_value_of_assets.item(),\n",
    "            latest_quarterly_earnings=latest_quarterly_earnings.item(),\n",
    "            price_history=price_history.numpy(),\n",
    "            quality_of_leadership=quality_of_leadership.item(),\n",
    "            stock_volatility=0.5\n",
    "        )\n",
    "\n",
    "        output.append(stock.get_stock_features())\n",
    "\n",
    "    return torch.tensor(output)\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78affda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c57e3d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_30128\\894559234.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  return torch.tensor(output)\n",
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_30128\\894559234.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data = torch.tensor(data, dtype=torch.float32)\n",
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_30128\\894559234.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 5000\n",
    "VALID_RATIO = 0.15\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "stock_features = generate_example_stock_features(N_SAMPLES)\n",
    "stock_labels = stock_features[:, 0]\n",
    "\n",
    "stock_dataset = StockDataset(stock_features, stock_labels)\n",
    "val_length = int(N_SAMPLES * VALID_RATIO)\n",
    "test_length = int(N_SAMPLES * TEST_RATIO)\n",
    "train_length = N_SAMPLES - (val_length + test_length)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(stock_dataset, lengths=[train_length, val_length, test_length])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=val_length, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_length, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a173d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; training_loss: 547140.875; validation_loss: 520693.59375\n",
      "Epoch: 1; training_loss: 508854.1875; validation_loss: 458522.03125\n",
      "Epoch: 2; training_loss: 450500.28125; validation_loss: 401043.15625\n",
      "Epoch: 3; training_loss: 363854.8125; validation_loss: 348245.46875\n",
      "Epoch: 4; training_loss: 312204.375; validation_loss: 300271.5\n",
      "Epoch: 5; training_loss: 253293.890625; validation_loss: 256847.734375\n",
      "Epoch: 6; training_loss: 214372.5; validation_loss: 218066.453125\n",
      "Epoch: 7; training_loss: 155668.0; validation_loss: 183620.25\n",
      "Epoch: 8; training_loss: 156050.46875; validation_loss: 153664.78125\n",
      "Epoch: 9; training_loss: 144107.96875; validation_loss: 127444.140625\n",
      "Epoch: 10; training_loss: 117594.421875; validation_loss: 104827.2109375\n",
      "Epoch: 11; training_loss: 86032.75; validation_loss: 85707.6484375\n",
      "Epoch: 12; training_loss: 70727.9921875; validation_loss: 69893.484375\n",
      "Epoch: 13; training_loss: 55840.4453125; validation_loss: 57021.9609375\n",
      "Epoch: 14; training_loss: 46016.546875; validation_loss: 46914.7421875\n",
      "Epoch: 15; training_loss: 33910.12890625; validation_loss: 39284.66796875\n",
      "Epoch: 16; training_loss: 39517.01171875; validation_loss: 33854.671875\n",
      "Epoch: 17; training_loss: 30778.421875; validation_loss: 30232.154296875\n",
      "Epoch: 18; training_loss: 24569.564453125; validation_loss: 28127.19140625\n",
      "Epoch: 19; training_loss: 23550.73828125; validation_loss: 27250.849609375\n",
      "Epoch: 20; training_loss: 23472.349609375; validation_loss: 27273.4296875\n",
      "Epoch: 21; training_loss: 23324.16015625; validation_loss: 27878.341796875\n",
      "Epoch: 22; training_loss: 25450.662109375; validation_loss: 28823.1328125\n",
      "Epoch: 23; training_loss: 28169.3359375; validation_loss: 29889.59375\n",
      "Epoch: 24; training_loss: 29509.30078125; validation_loss: 30900.421875\n",
      "Epoch: 25; training_loss: 24592.08203125; validation_loss: 31733.353515625\n",
      "Epoch: 26; training_loss: 26448.130859375; validation_loss: 32307.0234375\n",
      "Epoch: 27; training_loss: 29955.12109375; validation_loss: 32547.119140625\n",
      "Epoch: 28; training_loss: 28727.392578125; validation_loss: 32380.7734375\n",
      "Epoch: 29; training_loss: 35877.1328125; validation_loss: 31835.560546875\n",
      "Epoch: 30; training_loss: 26554.29296875; validation_loss: 30850.41015625\n",
      "Epoch: 31; training_loss: 24917.2578125; validation_loss: 29600.125\n",
      "Epoch: 32; training_loss: 27800.91015625; validation_loss: 28136.30859375\n",
      "Epoch: 33; training_loss: 20297.294921875; validation_loss: 26465.72265625\n",
      "Epoch: 34; training_loss: 23539.76953125; validation_loss: 24724.4375\n",
      "Epoch: 35; training_loss: 23085.125; validation_loss: 22937.951171875\n",
      "Epoch: 36; training_loss: 16654.50390625; validation_loss: 21090.9765625\n",
      "Epoch: 37; training_loss: 15501.8203125; validation_loss: 19330.75\n",
      "Epoch: 38; training_loss: 18171.75390625; validation_loss: 17662.244140625\n",
      "Epoch: 39; training_loss: 12343.2451171875; validation_loss: 16096.322265625\n",
      "Epoch: 40; training_loss: 14173.3828125; validation_loss: 14713.7373046875\n",
      "Epoch: 41; training_loss: 12129.24609375; validation_loss: 13462.94921875\n",
      "Epoch: 42; training_loss: 10914.1513671875; validation_loss: 12355.5869140625\n",
      "Epoch: 43; training_loss: 8638.1943359375; validation_loss: 11378.7841796875\n",
      "Epoch: 44; training_loss: 11366.9404296875; validation_loss: 10550.1552734375\n",
      "Epoch: 45; training_loss: 8150.3564453125; validation_loss: 9841.4013671875\n",
      "Epoch: 46; training_loss: 7373.79541015625; validation_loss: 9253.0458984375\n",
      "Epoch: 47; training_loss: 8061.0224609375; validation_loss: 8761.75390625\n",
      "Epoch: 48; training_loss: 9191.9140625; validation_loss: 8353.0771484375\n",
      "Epoch: 49; training_loss: 8561.08984375; validation_loss: 7997.09912109375\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "\n",
    "model = MultiLayerPerceptron(\n",
    "    in_channels=13,\n",
    "    hidden_channels=[16, 32],\n",
    "    n_classes=1, \n",
    "    model_task=ModelTask.REGRESSOR\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    val_features, val_labels = next(iter(val_dataloader))\n",
    "\n",
    "    train_features = train_features.to(device)\n",
    "    train_labels = train_labels.to(device)\n",
    "    val_features = val_features.to(device)\n",
    "    val_labels = val_labels.to(device)\n",
    "\n",
    "    preds = model(train_features)\n",
    "    loss = loss_fun(preds, train_labels)\n",
    "\n",
    "    val_preds = model(val_features)\n",
    "    val_loss = loss_fun(val_preds, val_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {i}; training_loss: {loss}; validation_loss: {val_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62403a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7980.4883, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "print(loss_fun(model(test_features.to(device)), test_labels.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
