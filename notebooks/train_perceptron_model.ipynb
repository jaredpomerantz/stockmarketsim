{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02893dd",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b41bfeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22ae35338b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from simulator.objects.policies.architectures import ModelTask\n",
    "from simulator.objects.policies.architectures.perceptron import MultiLayerPerceptron\n",
    "from simulator.objects.stock import Stock\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddbe4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_stock_features(n_stocks: int) -> torch.Tensor:\n",
    "    output = []\n",
    "    noise_dist = torch.distributions.Normal(loc=0, scale=0.001)\n",
    "    for _ in range(n_stocks):\n",
    "        cash = torch.rand(size=(1,)) * 110000 - 10000\n",
    "        earning_value_of_assets = torch.rand(size=(1,)) * 20000 + 10000\n",
    "        latest_quarterly_earnings = torch.rand(size=(1,)) * 20000 + 10000\n",
    "        start_price = torch.rand(size=(1,)) * 1000 + 10\n",
    "        price_slope = torch.rand(size=(1,)) * 0.01 - 0.005\n",
    "        growth_component = start_price + price_slope * torch.arange(0, 1825)\n",
    "        noise_component = noise_dist.sample(sample_shape=(1825,))\n",
    "        price_history = growth_component + noise_component\n",
    "        quality_of_leadership = torch.rand(size=(1,))\n",
    "        stock = Stock(\n",
    "            cash=cash.item(),\n",
    "            earning_value_of_assets=earning_value_of_assets.item(),\n",
    "            latest_quarterly_earnings=latest_quarterly_earnings.item(),\n",
    "            price_history=price_history.numpy(),\n",
    "            quality_of_leadership=quality_of_leadership.item(),\n",
    "            stock_volatility=0.5,\n",
    "        )\n",
    "        stock_features = stock.get_stock_features()\n",
    "        stock_features[0] = -1.0\n",
    "\n",
    "        output.append(np.append(stock_features, 0))\n",
    "\n",
    "    return torch.tensor(output)\n",
    "\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78affda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c57e3d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_20124\\1483597986.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data = torch.tensor(data, dtype=torch.float32)\n",
      "C:\\Users\\pomer\\AppData\\Local\\Temp\\ipykernel_20124\\1483597986.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 5000\n",
    "VALID_RATIO = 0.15\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "# NOTE: SWITCH TO PERCENT ERROR LOSS OR SOME VARIANT\n",
    "\n",
    "stock_features = generate_example_stock_features(N_SAMPLES)\n",
    "# stock_labels = stock_features[:, 0]\n",
    "stock_labels = torch.rand(size=(N_SAMPLES,)) * 1000 + 10\n",
    "\n",
    "stock_dataset = StockDataset(stock_features, stock_labels)\n",
    "val_length = int(N_SAMPLES * VALID_RATIO)\n",
    "test_length = int(N_SAMPLES * TEST_RATIO)\n",
    "train_length = N_SAMPLES - (val_length + test_length)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    stock_dataset, lengths=[train_length, val_length, test_length]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=val_length, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_length, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a173d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; training_loss: 355529.375; validation_loss: 359284.21875\n",
      "Epoch: 1; training_loss: 298243.75; validation_loss: 359223.84375\n",
      "Epoch: 2; training_loss: 326114.1875; validation_loss: 359149.34375\n",
      "Epoch: 3; training_loss: 367620.0625; validation_loss: 359056.8125\n",
      "Epoch: 4; training_loss: 346980.625; validation_loss: 358940.25\n",
      "Epoch: 5; training_loss: 350514.65625; validation_loss: 358790.78125\n",
      "Epoch: 6; training_loss: 327190.78125; validation_loss: 358598.4375\n",
      "Epoch: 7; training_loss: 335710.1875; validation_loss: 358346.5625\n",
      "Epoch: 8; training_loss: 288286.4375; validation_loss: 358019.84375\n",
      "Epoch: 9; training_loss: 355728.46875; validation_loss: 357584.90625\n",
      "Epoch: 10; training_loss: 345547.1875; validation_loss: 357013.8125\n",
      "Epoch: 11; training_loss: 336193.0; validation_loss: 356247.5\n",
      "Epoch: 12; training_loss: 329509.5; validation_loss: 355215.09375\n",
      "Epoch: 13; training_loss: 346578.5625; validation_loss: 353816.84375\n",
      "Epoch: 14; training_loss: 355984.125; validation_loss: 351909.84375\n",
      "Epoch: 15; training_loss: 323124.125; validation_loss: 349316.71875\n",
      "Epoch: 16; training_loss: 292985.8125; validation_loss: 345757.8125\n",
      "Epoch: 17; training_loss: 343115.875; validation_loss: 341285.25\n",
      "Epoch: 18; training_loss: 291911.34375; validation_loss: 335553.84375\n",
      "Epoch: 19; training_loss: 345073.625; validation_loss: 327911.46875\n",
      "Epoch: 20; training_loss: 326765.625; validation_loss: 318007.84375\n",
      "Epoch: 21; training_loss: 337241.59375; validation_loss: 305593.4375\n",
      "Epoch: 22; training_loss: 297487.375; validation_loss: 290904.03125\n",
      "Epoch: 23; training_loss: 277371.1875; validation_loss: 277623.5\n",
      "Epoch: 24; training_loss: 310022.8125; validation_loss: 278672.96875\n",
      "Epoch: 25; training_loss: 222464.65625; validation_loss: 315817.5\n",
      "Epoch: 26; training_loss: 256830.375; validation_loss: 329112.59375\n",
      "Epoch: 27; training_loss: 278527.0; validation_loss: 308073.71875\n",
      "Epoch: 28; training_loss: 247689.5625; validation_loss: 284027.90625\n",
      "Epoch: 29; training_loss: 272107.125; validation_loss: 274313.6875\n",
      "Epoch: 30; training_loss: 228230.546875; validation_loss: 274986.65625\n",
      "Epoch: 31; training_loss: 271625.0; validation_loss: 279128.875\n",
      "Epoch: 32; training_loss: 282823.75; validation_loss: 283572.71875\n",
      "Epoch: 33; training_loss: 263695.25; validation_loss: 286775.875\n",
      "Epoch: 34; training_loss: 266355.5; validation_loss: 288074.28125\n",
      "Epoch: 35; training_loss: 286811.875; validation_loss: 287981.125\n",
      "Epoch: 36; training_loss: 283920.25; validation_loss: 285846.9375\n",
      "Epoch: 37; training_loss: 261008.1875; validation_loss: 282448.625\n",
      "Epoch: 38; training_loss: 298669.78125; validation_loss: 278076.25\n",
      "Epoch: 39; training_loss: 216927.03125; validation_loss: 273744.46875\n",
      "Epoch: 40; training_loss: 276890.75; validation_loss: 270804.59375\n",
      "Epoch: 41; training_loss: 268276.9375; validation_loss: 271519.34375\n",
      "Epoch: 42; training_loss: 281146.5; validation_loss: 278399.5625\n",
      "Epoch: 43; training_loss: 208896.375; validation_loss: 291908.125\n",
      "Epoch: 44; training_loss: 309303.3125; validation_loss: 303174.6875\n",
      "Epoch: 45; training_loss: 276760.625; validation_loss: 283515.9375\n",
      "Epoch: 46; training_loss: 274040.3125; validation_loss: 271692.59375\n",
      "Epoch: 47; training_loss: 270483.8125; validation_loss: 268829.8125\n",
      "Epoch: 48; training_loss: 233519.546875; validation_loss: 270431.6875\n",
      "Epoch: 49; training_loss: 250180.46875; validation_loss: 273517.21875\n",
      "Epoch: 50; training_loss: 263999.0; validation_loss: 276029.125\n",
      "Epoch: 51; training_loss: 299731.96875; validation_loss: 277167.25\n",
      "Epoch: 52; training_loss: 268785.71875; validation_loss: 277269.75\n",
      "Epoch: 53; training_loss: 294359.875; validation_loss: 276568.40625\n",
      "Epoch: 54; training_loss: 241857.21875; validation_loss: 275012.96875\n",
      "Epoch: 55; training_loss: 246335.625; validation_loss: 272685.0625\n",
      "Epoch: 56; training_loss: 228305.5; validation_loss: 270242.15625\n",
      "Epoch: 57; training_loss: 263869.1875; validation_loss: 267394.125\n",
      "Epoch: 58; training_loss: 271630.375; validation_loss: 264686.15625\n",
      "Epoch: 59; training_loss: 249829.1875; validation_loss: 263387.34375\n",
      "Epoch: 60; training_loss: 220988.203125; validation_loss: 264530.5\n",
      "Epoch: 61; training_loss: 333507.28125; validation_loss: 267778.96875\n",
      "Epoch: 62; training_loss: 251283.328125; validation_loss: 271330.84375\n",
      "Epoch: 63; training_loss: 238584.0625; validation_loss: 275755.6875\n",
      "Epoch: 64; training_loss: 261270.890625; validation_loss: 271255.03125\n",
      "Epoch: 65; training_loss: 236227.78125; validation_loss: 262202.84375\n",
      "Epoch: 66; training_loss: 250972.78125; validation_loss: 256561.40625\n",
      "Epoch: 67; training_loss: 248786.28125; validation_loss: 252566.65625\n",
      "Epoch: 68; training_loss: 269033.1875; validation_loss: 249960.890625\n",
      "Epoch: 69; training_loss: 242020.078125; validation_loss: 247603.875\n",
      "Epoch: 70; training_loss: 195077.1875; validation_loss: 245429.15625\n",
      "Epoch: 71; training_loss: 231283.625; validation_loss: 243655.609375\n",
      "Epoch: 72; training_loss: 205888.09375; validation_loss: 240801.5625\n",
      "Epoch: 73; training_loss: 196124.703125; validation_loss: 238118.203125\n",
      "Epoch: 74; training_loss: 237222.171875; validation_loss: 235288.1875\n",
      "Epoch: 75; training_loss: 254235.46875; validation_loss: 232529.515625\n",
      "Epoch: 76; training_loss: 226088.625; validation_loss: 229705.390625\n",
      "Epoch: 77; training_loss: 237135.859375; validation_loss: 227110.15625\n",
      "Epoch: 78; training_loss: 201237.953125; validation_loss: 225704.65625\n",
      "Epoch: 79; training_loss: 217080.0; validation_loss: 224441.0625\n",
      "Epoch: 80; training_loss: 192189.65625; validation_loss: 224648.0\n",
      "Epoch: 81; training_loss: 269230.5; validation_loss: 225316.28125\n",
      "Epoch: 82; training_loss: 193282.25; validation_loss: 221274.578125\n",
      "Epoch: 83; training_loss: 197205.9375; validation_loss: 219083.390625\n",
      "Epoch: 84; training_loss: 233939.25; validation_loss: 218111.3125\n",
      "Epoch: 85; training_loss: 232374.640625; validation_loss: 218316.328125\n",
      "Epoch: 86; training_loss: 184887.640625; validation_loss: 218267.9375\n",
      "Epoch: 87; training_loss: 210882.34375; validation_loss: 217224.703125\n",
      "Epoch: 88; training_loss: 193630.03125; validation_loss: 215104.171875\n",
      "Epoch: 89; training_loss: 152979.0625; validation_loss: 213758.125\n",
      "Epoch: 90; training_loss: 204686.09375; validation_loss: 213860.609375\n",
      "Epoch: 91; training_loss: 215142.875; validation_loss: 215287.0\n",
      "Epoch: 92; training_loss: 182581.59375; validation_loss: 216290.515625\n",
      "Epoch: 93; training_loss: 226335.578125; validation_loss: 217944.046875\n",
      "Epoch: 94; training_loss: 179237.03125; validation_loss: 218705.6875\n",
      "Epoch: 95; training_loss: 213330.875; validation_loss: 218063.65625\n",
      "Epoch: 96; training_loss: 190676.15625; validation_loss: 217670.859375\n",
      "Epoch: 97; training_loss: 189635.09375; validation_loss: 215295.90625\n",
      "Epoch: 98; training_loss: 148008.828125; validation_loss: 213333.75\n",
      "Epoch: 99; training_loss: 192080.25; validation_loss: 212409.21875\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "\n",
    "model = MultiLayerPerceptron(\n",
    "    in_channels=14,\n",
    "    hidden_channels=[16, 32],\n",
    "    n_classes=1,\n",
    "    model_task=ModelTask.REGRESSOR,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    val_features, val_labels = next(iter(val_dataloader))\n",
    "\n",
    "    train_features = train_features.to(device)\n",
    "    train_labels = train_labels.to(device)\n",
    "    val_features = val_features.to(device)\n",
    "    val_labels = val_labels.to(device)\n",
    "\n",
    "    preds = model(train_features)\n",
    "    loss = loss_fun(preds, train_labels)\n",
    "\n",
    "    val_preds = model(val_features)\n",
    "    val_loss = loss_fun(val_preds, val_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch: {i}; training_loss: {loss}; validation_loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62403a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(200391.0781, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "print(loss_fun(model(test_features.to(device)), test_labels.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaad38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_naive_price.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
